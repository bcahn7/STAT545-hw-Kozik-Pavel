### Homework 7 STAT 545

Here is a [link to the final md file of homework 7](https://github.com/Kozp/STAT545-hw-Kozik-Pavel/blob/Side-Branch/hw07%20-%20Scripts%20and%20Make/Script4_Report.md). Two different methods were done to create this fine. One option is through a master R script in which *source* and *rmarkdown::render* were used. Here is a [link to that file](https://github.com/Kozp/STAT545-hw-Kozik-Pavel/blob/Side-Branch/hw07%20-%20Scripts%20and%20Make/Script5_Master.R). The other option was to create the final .md file via *make*. Here is a [link to the make file](https://github.com/Kozp/STAT545-hw-Kozik-Pavel/blob/Side-Branch/hw07%20-%20Scripts%20and%20Make/makefile).

Regardless of whether the *master R script*, or *make file* were used, both produced the same output md. In either case data was first downloaded via [Script1_Download.R](https://github.com/Kozp/STAT545-hw-Kozik-Pavel/blob/Side-Branch/hw07%20-%20Scripts%20and%20Make/Script1_Download.R). Data were then cleaned, organized, and sorted into a coherent and manageable structure through [Script2_DataCleaning_and_prep.R](https://github.com/Kozp/STAT545-hw-Kozik-Pavel/blob/Side-Branch/hw07%20-%20Scripts%20and%20Make/Script2_DataCleaning_and_prep.R). Next visualizations were created and saved by running data through [Script3_Visualization.R](https://github.com/Kozp/STAT545-hw-Kozik-Pavel/blob/Side-Branch/hw07%20-%20Scripts%20and%20Make/Script3_Visualization.R). Lastly, the visualizations were presented with text and interpretation through an R markdown file called [Script4_Report.Rmd](https://github.com/Kozp/STAT545-hw-Kozik-Pavel/blob/Side-Branch/hw07%20-%20Scripts%20and%20Make/Script4_Report.Rmd).


###Progress Report

The task was an enjoyable one in that, should my interpretation be correct, we had free reign to find a data set we were interested in and were free to determine what analysis we conducted. I used this opportunity to look at [Vancouver census data](http://data.vancouver.ca/datacatalogue/index.htm) of which I had known and was interested in but had lacked an opportunity to capitalize on. Similarly choosing what variables were of interest and what question to persue allowed for an air of freedom. 

After downloading the data, considerable time was required to clean and sort it into something more managable. For instance, rows and columns had to be moved, grouped, removed, renamed and otherwise organized. The task allowed for an opportunity to work with a dataset not already in a easily workable r format, unlike say gapminder.   

A difficult aspect was combining and automating all the seperate scripts. I had not prior created a master script, or used make, and so a great deal of trial and error came into play. After successfully having a master R script run correctly, I then attempted running a make file. This required considerably more resources and time. I reviewed the course website examples of make files to understand the correct grammar and syntax, however this was only partly helpful. Time had to be invested into understanding the logic and flow of a make file, something that unlikely cannot be explicity stated but just thought on and reflected over. For instance, although obvious now, it was not immediately transparent that data structures had to be saved and transferred from one script into the next. The functions  *saveRDS* and *readRDS* also did not jump to mind so for a period of time I worked with .dat, .xls and other formats.

